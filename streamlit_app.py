import streamlit as st
from openai import OpenAI

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì¸ì‚¬ ì„œë¥˜ ì•ˆë‚´ ì±—ë´‡",
    page_icon="ğŸ“‹",
    layout="centered",
)

st.title("ğŸ“‹ ì¸ì‚¬ ì„œë¥˜ ì•ˆë‚´ ì±—ë´‡")
st.caption("ìœ¡ì•„íœ´ì§ ë° 4ëŒ€ë³´í—˜ í”¼ë¶€ì–‘ì ë“±ë¡ ê´€ë ¨ ì„œë¥˜ë¥¼ ì•ˆë‚´í•´ë“œë¦½ë‹ˆë‹¤.")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@st.cache_resource
def get_openai_client():
    try:
        return OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    except Exception:
        st.error("OPENAI_API_KEYê°€ secrets.tomlì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()

client = get_openai_client()

# ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ì •ì˜
FAQ_QUESTIONS = [
    "4ëŒ€ë³´í—˜ í”¼ë¶€ì–‘ì ë“±ë¡ì„ í•˜ë ¤ë©´ ì–´ë–¤ ì„œë¥˜ë¥¼ ì œì¶œí•´ì•¼ í•˜ë‚˜ìš”?",
    "ìœ¡ì•„íœ´ì§ ì‹ ì²­ ì‹œ ì œì¶œí•´ì•¼ í•  ì„œë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    "ìœ¡ì•„íœ´ì§ 1ë…„ ì‚¬ìš© í›„ 6ê°œì›” ì—°ì¥ ì‹œ í•„ìš”í•œ ì„œë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    "ìœ¡ì•„íœ´ì§ ê¸‰ì—¬ë¥¼ ì–¼ë§ˆë‚˜ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?",
    "ì¶œì‚°íœ´ê°€ í›„ ìœ¡ì•„íœ´ì§ ë°”ë¡œ ì „í™˜í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
]

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì¸ì‚¬ ì„œë¥˜ ì œì¶œì„ ì•ˆë‚´í•˜ëŠ” ì¹œì ˆí•œ HR ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì£¼ìš” ì•ˆë‚´ ì‚¬í•­:

**ìœ¡ì•„íœ´ì§ ê¸‰ì—¬ ì‹ ì²­ì„ ìœ„í•œ ìë…€ ì •ë³´ ì œì¶œ ì•ˆë‚´:**
- ê³µë¬¸ìœ¼ë¡œ ìœ¡ì•„íœ´ì§ ì‹ ì²­ì„œ ì œì¶œ ì‹œ ìë…€ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë’·ìë¦¬ê°€ ê¸°ì¬ëœ ê°€ì¡±ê´€ê³„ì¦ëª…ì„œë¥¼ ì²¨ë¶€í•´ ì£¼ì„¸ìš”.
- ê°œì¸ì •ë³´ì¸ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ê³µë¬¸ ì²¨ë¶€ê°€ ìš°ë ¤ë˜ë©´ HR ë‹´ë‹¹ì ì´ë©”ì¼ë¡œ ë³„ë„ ì†¡ë¶€í•´ ì£¼ì„¸ìš”.
- ìœ¡ì•„íœ´ì§ ê¸‰ì—¬ ì§€ê¸‰ì„ ìœ„í•œ ì‹ ì²­ì„œ ì œì¶œ ì‹œ ìë…€ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤(ê³ ìš©ì„¼í„° í•„ìˆ˜ í™•ì¸ì‚¬í•­).
- ì‚°ì „ íœ´ì§ì´ë©´ ìë…€ ì£¼ë¯¼ë²ˆí˜¸ë¥¼ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ í•´ë‹¹ ì—†ìŒ.

**1ë…„ ìœ¡ì•„íœ´ì§ ì‚¬ìš© í›„ ì—°ì¥ ì‹ ì²­ ì‹œ ì¶”ê°€ ì¦ë¹™ ì•ˆë‚´:**
- ìœ¡ì•„íœ´ì§ ê¸‰ì—¬ ëŒ€ìƒê¸°ê°„ì€ 1ë…„ì´ë©°, ë¶€ë¶€ê°€ ëª¨ë‘ ìœ¡ì•„íœ´ì§ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì— í•œí•´ 1ë…„ 6ê°œì›”ê¹Œì§€ ì§€ê¸‰ë©ë‹ˆë‹¤.
- ìµœì´ˆ 1ë…„ ì‚¬ìš© í›„ ì¶”ê°€ 6ê°œì›” ì—°ì¥ ì‹œ, ë°°ìš°ìê°€ ë™ì‹œì— 3ê°œì›” ì´ìƒ ìœ¡ì•„íœ´ì§ì„ ì‚¬ìš©í–ˆë‹¤ëŠ” ì¦ë¹™ìë£Œë¥¼ ì œì¶œí•´ ì£¼ì„¸ìš”. ì—†ìœ¼ë©´ ì œì¶œ ë¶ˆí•„ìš”.
- ë°°ìš°ìê°€ ë™ì‹œì— 3ê°œì›” ì´ìƒ ìœ¡ì•„íœ´ì§ì„ ì‚¬ìš©í–ˆë‹¤ëŠ” ì¦ë¹™ìë£Œ:
  * ê°™ì€ ìë…€ë¥¼ ëŒ€ìƒìœ¼ë¡œ ë¶€ëª¨ê°€ ëª¨ë‘ ìœ¡ì•„íœ´ì§ì„ ê°ê° 3ê°œì›” ì´ìƒ ì‚¬ìš©í•œ ê²½ìš°ì˜ ë¶€ ë˜ëŠ” ëª¨
  * ì¦ë¹™ìë£Œ ì˜ˆì‹œ: â–²ìœ¡ì•„íœ´ì§ê¸‰ì—¬ ì§€ê¸‰ ê²°ì • í†µì§€ì„œ, â–²íšŒì‚¬ì—ì„œ ê³µì‹ì ìœ¼ë¡œ ë°œë ¹í•œ íœ´ì§-ë³µì§ ë°œë ¹ë¬¸(íœ´ì§ ë°œë ¹ë¬¸ë§Œìœ¼ë¡œëŠ” ì‹¤ì œ íœ´ì§ì—¬ë¶€ë¥¼ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë³µì§ ë°œë ¹ë¬¸ë„ í•¨ê»˜ í™•ì¸ í•„ìš”)

**ìœ¡ì•„íœ´ì§ ì‹ ì²­ ì‹œ ê¸°ë³¸ í•„ìš” ì„œë¥˜:**
1. ìœ¡ì•„íœ´ì§ ì‹ ì²­ì„œ
2. ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ (ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë’·ìë¦¬ í¬í•¨)

**ì¶œì‚°íœ´ê°€ í›„ ìœ¡ì•„íœ´ì§ ë°”ë¡œ ì „í™˜:**
- í†µí•©ì‹ ì²­ì„œë¥¼ ì œì¶œí•˜ë©´ ë©ë‹ˆë‹¤.
- í†µí•©ì‹ ì²­ì„œ ì‘ì„± í•­ëª©:
  1. ì‹ ì²­ì¸ì˜ ì„±ëª…, ìƒë…„ì›”ì¼ ë“± ì¸ì ì‚¬í•­
  2. ìœ¡ì•„íœ´ì§ ëŒ€ìƒì¸ ì˜ìœ ì•„ì˜ ì„±ëª…Â·ìƒë…„ì›”ì¼
  3. íœ´ì§ê°œì‹œì˜ˆì •ì¼
  4. ìœ¡ì•„íœ´ì§ì„ ì¢…ë£Œí•˜ë ¤ëŠ” ë‚ 
  5. ìœ¡ì•„íœ´ì§ ì‹ ì²­ ì—°ì›”ì¼
  6. ì¶œì‚°ì „í›„íœ´ê°€ ë˜ëŠ” ë°°ìš°ìì¶œì‚°íœ´ê°€ ê°œì‹œì˜ˆì •ì¼ ë° ì¢…ë£Œì¼(í†µí•©ì‹ ì²­ì‹œì—ë§Œ ê¸°ì¬)
- ìì„¸í•œ ë‚´ìš©ì€ ë§í¬ ì°¸ê³ : https://www.moel.go.kr/news/notice/noticeView.do?bbs_seq=20250100161

**4ëŒ€ë³´í—˜ í”¼ë¶€ì–‘ì ë“±ë¡ ì‹œ í•„ìš” ì„œë¥˜:**
- í”¼ë¶€ì–‘ì ëª…ì˜ì˜ ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ (ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë’·ìë¦¬ í¬í•¨), ì œì¶œì²˜ëŠ” íšŒì‚¬ ì¸ì‚¬ë¶€ì„œ ë‹´ë‹¹ì.

**ì¶”ê°€ ì°¸ê³  ì‚¬í•­:**
- ê°€ì¡±ê´€ê³„ì¦ëª…ì„œëŠ” ì£¼ë¯¼ì„¼í„° ë˜ëŠ” ì •ë¶€24ì—ì„œ ë°œê¸‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë’·ìë¦¬ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
- ë°œê¸‰ì¼ë¡œë¶€í„° 3ê°œì›” ì´ë‚´ ì„œë¥˜ë¥¼ ì œì¶œí•´ì•¼ í•©ë‹ˆë‹¤.

**ìœ¡ì•„íœ´ì§ ê¸‰ì—¬ ê´€ë ¨:**
- ìœ¡ì•„íœ´ì§ê¸‰ì—¬ëŠ” ê³ ìš©ë³´í—˜ì— ê°€ì…í•´ ìˆëŠ” í”¼ë³´í—˜ìê°€ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë¯¸ë¦¬ ì•Œì•„ë³´ëŠ” ë‚˜ì˜ ìœ¡ì•„íœ´ì§ê¸‰ì—¬ ì§€ê¸‰ì•¡ ëª¨ì˜ê³„ì‚°: https://www.work24.go.kr/cm/c/f/1100/selecSimulate12.do?currentPageNo=1&recordCountPerPage=10&upprSystClId=SC00000245&systClId=SC00000251&systId=SI00000402&systCnntId=CI00001626
- ìœ¡ì•„íœ´ì§ê¸‰ì—¬ì— ê´€í•œ ê¸‰ì—¬ëª¨ì˜ê³„ì‚°ì€ ê³ ìš©ë³´í—˜ì— ê°€ì…í•´ ìˆëŠ” í”¼ë³´í—˜ìê°€ ìœ¡ì•„íœ´ì§ê¸‰ì—¬ë¥¼ ë°›ê²Œë  ê²½ìš° ë°›ê²Œ ë  ìœ¡ì•„íœ´ì§ê¸‰ì—¬ë¥¼ ê³„ì‚°í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë”°ë¼ í•„ìš”í•œ ì„œë¥˜ë¥¼ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì•ˆë‚´í•˜ì„¸ìš”. ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ê³ , ì¶”ê°€ ê¶ê¸ˆí•œ ì‚¬í•­ì„ ë¬»ìŠµë‹ˆë‹¤."""

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": "ì•ˆë…•í•˜ì„¸ìš”! ìœ¡ì•„íœ´ì§ì´ë‚˜ 4ëŒ€ë³´í—˜ í”¼ë¶€ì–‘ì ë“±ë¡ê³¼ ê´€ë ¨í•˜ì—¬ í•„ìš”í•œ ì„œë¥˜ë¥¼ ì•ˆë‚´í•´ë“œë¦½ë‹ˆë‹¤. ì–´ë–¤ ê²ƒì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?",
        }
    ]

# ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# FAQì—ì„œ ì¶”ê°€ëœ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ AI ì‘ë‹µ ìƒì„±
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    last_message = st.session_state.messages[-1]
    # ì´ë¯¸ ì‘ë‹µì´ ìƒì„±ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì‘ë‹µ ìƒì„±
    needs_response = True
    if len(st.session_state.messages) >= 2:
        if st.session_state.messages[-2]["role"] == "assistant":
            # ì´ì „ ë©”ì‹œì§€ê°€ assistantì´ë©´ ìƒˆë¡œìš´ user ë©”ì‹œì§€ì— ëŒ€í•œ ì‘ë‹µ í•„ìš”
            needs_response = True
    
    if needs_response and last_message["content"] in FAQ_QUESTIONS:
        with st.chat_message("assistant"):
            placeholder = st.empty()
            full_response = ""

            try:
                messages_for_api = [{"role": "system", "content": SYSTEM_PROMPT}] + st.session_state.messages
                stream = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages_for_api,
                    stream=True,
                    temperature=0.7,
                    max_tokens=1000,
                )

                for chunk in stream:
                    delta = chunk.choices[0].delta.content if chunk.choices else None
                    if delta:
                        full_response += delta
                        placeholder.markdown(full_response + "â–Œ")
                placeholder.markdown(full_response)
            except Exception as e:
                full_response = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                placeholder.error(full_response)

        st.session_state.messages.append({"role": "assistant", "content": full_response})
        st.rerun()

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_response = ""

        try:
            messages_for_api = [{"role": "system", "content": SYSTEM_PROMPT}] + st.session_state.messages
            stream = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages_for_api,
                stream=True,
                temperature=0.7,
                max_tokens=1000,
            )

            for chunk in stream:
                delta = chunk.choices[0].delta.content if chunk.choices else None
                if delta:
                    full_response += delta
                    placeholder.markdown(full_response + "â–Œ")
            placeholder.markdown(full_response)
        except Exception as e:
            full_response = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            placeholder.error(full_response)

    st.session_state.messages.append({"role": "assistant", "content": full_response})

# ì‚¬ì´ë“œë°”ì— ì•ˆë‚´ ì •ë³´ ì¶”ê°€
with st.sidebar:
    st.header("ğŸ“Œ ì£¼ìš” ì•ˆë‚´")
    st.markdown("### ìì£¼ ë¬»ëŠ” ì§ˆë¬¸")
    st.caption("ì§ˆë¬¸ì„ í´ë¦­í•˜ë©´ ì±—ë´‡ì´ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")
    
    for i, question in enumerate(FAQ_QUESTIONS, 1):
        if st.button(f"Q{i}: {question}", key=f"faq_{i}", use_container_width=True):
            # FAQ ì§ˆë¬¸ì„ ì±„íŒ…ì— ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": question})
            st.rerun()

    st.divider()
    
    if st.button("ëŒ€í™” ì´ˆê¸°í™”", type="secondary", use_container_width=True):
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": "ì•ˆë…•í•˜ì„¸ìš”! ìœ¡ì•„íœ´ì§ì´ë‚˜ 4ëŒ€ë³´í—˜ í”¼ë¶€ì–‘ì ë“±ë¡ê³¼ ê´€ë ¨í•˜ì—¬ í•„ìš”í•œ ì„œë¥˜ë¥¼ ì•ˆë‚´í•´ë“œë¦½ë‹ˆë‹¤. ì–´ë–¤ ê²ƒì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?",
            }
        ]
        st.rerun()
